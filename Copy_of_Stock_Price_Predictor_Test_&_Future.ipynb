{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Stock Price Predictor Test & Future.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Xl9qCzQsUo"
      },
      "source": [
        "# Enter Stock Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LAWLca7Qm3e",
        "outputId": "3cfec60d-8ace-49b9-ee4f-8b5a943bb6b4"
      },
      "source": [
        "stock = input('Please enter Ticker Symbol(e.g. AAPL) & Press Enter: ')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter Ticker Symbol(e.g. AAPL) & Press Enter: AAPL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z33xOjedQ3Ug"
      },
      "source": [
        "# Getting Data & Calculating Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ0G3FG5Q2sA",
        "outputId": "3b4e0783-641f-480e-8952-6674b474110a"
      },
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        " \n",
        "# get data / handle time / convert to numpy array\n",
        "now = int(time.time()) \n",
        "now =str(now)\n",
        "days_delta = int(time.time()) - 12500000 * 3   #102 days of stock onfo\n",
        "days =str(days_delta)\n",
        "r = requests.get('https://finnhub.io/api/v1/stock/candle?symbol='+stock+'&from='+days+'&to='+now+'&resolution=D&token=c36j4jqad3ifoi8hsu50')\n",
        "j = r.json() \n",
        "df = pd.DataFrame.from_dict(j)\n",
        "df.t = (pd.to_datetime(df['t'],unit='s'))\n",
        "df_close = df[['t','c']]\n",
        "all_close = df_close['c'].values.astype(float)\n",
        " \n",
        "# libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "# model building\n",
        "train=all_close[:-15].reshape(-1, 1)\n",
        "test=all_close[-15:].reshape(-1, 1)\n",
        "scaler=MinMaxScaler()\n",
        "scaled_train=scaler.fit_transform(train)\n",
        "scaled_test=scaler.transform(test)\n",
        " \n",
        "n_input= len(train) - 1\n",
        "n_features=1\n",
        " \n",
        "train_generator=TimeseriesGenerator(scaled_train,\n",
        "                                     scaled_train,\n",
        "                                      n_input,\n",
        "                                      batch_size=1)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping()\n",
        " \n",
        "custom_early_stopping = EarlyStopping(   \n",
        "    monitor='loss', \n",
        "    patience=35, \n",
        "    min_delta=0.009, \n",
        "    mode='min' # was max\n",
        ")\n",
        "model=Sequential()\n",
        "model.add(LSTM(100,activation='relu',input_shape=(n_input,n_features),return_sequences=True))\n",
        "model.add(LSTM(50,activation='relu',return_sequences=True))\n",
        "model.add(LSTM(10,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        " \n",
        "##\n",
        " \n",
        "model.fit(train_generator,epochs=140, callbacks=[custom_early_stopping])\n",
        " \n",
        "test_predictions = []\n",
        "#Select last n_input values from the train data\n",
        "first_eval_batch = scaled_train[-n_input:]\n",
        "#reshape the data into LSTM required (#batch,#timesteps,#features)\n",
        "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
        "for i in range(len(test)):\n",
        "# get prediction, grab the exact number using the [0]\n",
        "  pred = model.predict(current_batch)[0]\n",
        "# Add this prediction to the list\n",
        "  test_predictions.append(pred)\n",
        "# The most critical part, update the (#batch,#timesteps,#features\n",
        "# using np.append(\n",
        "# current_batch[:        ,1:   ,:] ---------> read this as\n",
        "# current_batch[no_change,1:end,no_change]\n",
        "# (Do note the second part has the timesteps)\n",
        "# [[pred]] need the double brackets as current_batch is a 3D array\n",
        "# axis=1, remember we need to add to the second part i.e. 1st axis\n",
        "  current_batch = np.append(current_batch[:,1:,:],[[pred]],axis=1)\n",
        " \n",
        " \n",
        "actual_predictions = scaler.inverse_transform(test_predictions)\n",
        "rows =list(range(len(train), len(train)+15)) # this\n",
        "pred_df = pd.DataFrame(data=actual_predictions,index=rows)\n",
        " \n",
        "future_train = all_close.reshape(-1,1)\n",
        "scaled_future_train=scaler.fit_transform(future_train)\n",
        "n_input= len(future_train) - 1\n",
        "n_features=1\n",
        " \n",
        "future_generator=TimeseriesGenerator(scaled_future_train,\n",
        "                                     scaled_future_train,\n",
        "                                      n_input,\n",
        "                                      batch_size=1)\n",
        "custom_early_stopping = EarlyStopping(   \n",
        "    monitor='loss', \n",
        "    patience=35, \n",
        "    min_delta=0.009, \n",
        "    mode='min'\n",
        ")\n",
        " \n",
        "model=Sequential()\n",
        "model.add(LSTM(100,activation='relu',input_shape=(n_input,n_features),return_sequences=True))\n",
        "model.add(LSTM(50,activation='relu',return_sequences=True))\n",
        "model.add(LSTM(10,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        " \n",
        " \n",
        " \n",
        " \n",
        "model.fit(future_generator,epochs=140, callbacks=[custom_early_stopping])\n",
        " \n",
        "future_predictions = []\n",
        "#Select last n_input values from the train data\n",
        "first_eval_batch = scaled_future_train[-n_input:]\n",
        "#reshape the data into LSTM required (#batch,#timesteps,#features)\n",
        "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
        "for i in range(len(test)):\n",
        "# get prediction, grab the exact number using the [0]\n",
        "  pred = model.predict(current_batch)[0]\n",
        "# Add this prediction to the list\n",
        "  future_predictions.append(pred)\n",
        "# The most critical part, update the (#batch,#timesteps,#features\n",
        "# using np.append(\n",
        "# current_batch[:        ,1:   ,:] ---------> read this as\n",
        "# current_batch[no_change,1:end,no_change]\n",
        "# (Do note the second part has the timesteps)\n",
        "# [[pred]] need the double brackets as current_batch is a 3D array\n",
        "# axis=1, remember we need to add to the second part i.e. 1st axis\n",
        "  current_batch = np.append(current_batch[:,1:,:],[[pred]],axis=1)\n",
        " \n",
        " \n",
        "future_actual_predictions = scaler.inverse_transform(future_predictions)\n",
        "rows =list(range(len(future_train),len(future_train)+15))\n",
        "future_pred_df = pd.DataFrame(data=future_actual_predictions,index=rows)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/140\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.0186\n",
            "Epoch 2/140\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.9954\n",
            "Epoch 3/140\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.9894\n",
            "Epoch 4/140\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.9865\n",
            "Epoch 5/140\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.9706\n",
            "Epoch 6/140\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.9474\n",
            "Epoch 7/140\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.9236\n",
            "Epoch 8/140\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.8974\n",
            "Epoch 9/140\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.8725\n",
            "Epoch 10/140\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.8453\n",
            "Epoch 11/140\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.8157\n",
            "Epoch 12/140\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.7829\n",
            "Epoch 13/140\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.7461\n",
            "Epoch 14/140\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.7031\n",
            "Epoch 15/140\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.6472\n",
            "Epoch 16/140\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.5777\n",
            "Epoch 17/140\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.5030\n",
            "Epoch 18/140\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.4121\n",
            "Epoch 19/140\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.2958\n",
            "Epoch 20/140\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.1510\n",
            "Epoch 21/140\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0096\n",
            "Epoch 22/140\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.4053\n",
            "Epoch 23/140\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.0884\n",
            "Epoch 24/140\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 9.9807e-04\n",
            "Epoch 25/140\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.0174\n",
            "Epoch 26/140\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.0535\n",
            "Epoch 27/140\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.0851\n",
            "Epoch 28/140\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.1073\n",
            "Epoch 29/140\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.1199\n",
            "Epoch 30/140\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.1235\n",
            "Epoch 31/140\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.1196\n",
            "Epoch 32/140\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.1095\n",
            "Epoch 33/140\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.0939\n",
            "Epoch 34/140\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0743\n",
            "Epoch 35/140\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.0521\n",
            "Epoch 36/140\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.0299\n",
            "Epoch 37/140\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.0112\n",
            "Epoch 38/140\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 6.8299e-04\n",
            "Epoch 39/140\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.0038\n",
            "Epoch 40/140\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.0195\n",
            "Epoch 41/140\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0329\n",
            "Epoch 42/140\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0323\n",
            "Epoch 43/140\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.0209\n",
            "Epoch 44/140\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0086\n",
            "Epoch 45/140\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0015\n",
            "Epoch 46/140\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 1.0418e-04\n",
            "Epoch 47/140\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.0025\n",
            "Epoch 48/140\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0061\n",
            "Epoch 49/140\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.0091\n",
            "Epoch 50/140\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0106\n",
            "Epoch 51/140\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.0105\n",
            "Epoch 52/140\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.0089\n",
            "Epoch 53/140\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0065\n",
            "Epoch 54/140\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0038\n",
            "Epoch 55/140\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0015\n",
            "Epoch 56/140\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 2.3843e-04\n",
            "Epoch 57/140\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 6.5911e-05\n",
            "Epoch 58/140\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 8.5254e-04\n",
            "Epoch 59/140\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.0021\n",
            "Epoch 60/140\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.0031\n",
            "Epoch 61/140\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.0035\n",
            "Epoch 62/140\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0030\n",
            "Epoch 63/140\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0021\n",
            "Epoch 64/140\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.0010\n",
            "Epoch 65/140\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 2.9838e-04\n",
            "Epoch 66/140\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 5.5213e-06\n",
            "Epoch 67/140\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 1.2214e-04\n",
            "Epoch 68/140\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 4.8085e-04\n",
            "Epoch 69/140\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 8.8096e-04\n",
            "Epoch 70/140\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.0012\n",
            "Epoch 71/140\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.0012\n",
            "Epoch 72/140\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.0011\n",
            "Epoch 73/140\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 7.9373e-04\n",
            "Epoch 74/140\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 4.5307e-04\n",
            "Epoch 75/140\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 1.6968e-04\n",
            "Epoch 76/140\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 1.7775e-05\n",
            "Epoch 77/140\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 1.8302e-05\n",
            "Epoch 78/140\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 1.3522e-04\n",
            "Epoch 79/140\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 2.9373e-04\n",
            "Epoch 80/140\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 4.1377e-04\n",
            "Epoch 81/140\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 4.4359e-04\n",
            "Epoch 1/140\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9596\n",
            "Epoch 2/140\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.9191\n",
            "Epoch 3/140\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.8904\n",
            "Epoch 4/140\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.8588\n",
            "Epoch 5/140\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.8248\n",
            "Epoch 6/140\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.7891\n",
            "Epoch 7/140\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.7521\n",
            "Epoch 8/140\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.7085\n",
            "Epoch 9/140\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6575\n",
            "Epoch 10/140\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.5982\n",
            "Epoch 11/140\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.5326\n",
            "Epoch 12/140\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.4548\n",
            "Epoch 13/140\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.3592\n",
            "Epoch 14/140\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.2422\n",
            "Epoch 15/140\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.1068\n",
            "Epoch 16/140\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 2.6072e-04\n",
            "Epoch 17/140\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.4304\n",
            "Epoch 18/140\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.0980\n",
            "Epoch 19/140\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0022\n",
            "Epoch 20/140\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.0128\n",
            "Epoch 21/140\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.0432\n",
            "Epoch 22/140\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.0710\n",
            "Epoch 23/140\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0907\n",
            "Epoch 24/140\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.1016\n",
            "Epoch 25/140\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1045\n",
            "Epoch 26/140\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.1006\n",
            "Epoch 27/140\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.0913\n",
            "Epoch 28/140\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.0775\n",
            "Epoch 29/140\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.0619\n",
            "Epoch 30/140\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0453\n",
            "Epoch 31/140\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0282\n",
            "Epoch 32/140\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.0128\n",
            "Epoch 33/140\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.0022\n",
            "Epoch 34/140\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 9.1251e-04\n",
            "Epoch 35/140\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0109\n",
            "Epoch 36/140\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.0232\n",
            "Epoch 37/140\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0250\n",
            "Epoch 38/140\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.0166\n",
            "Epoch 39/140\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0068\n",
            "Epoch 40/140\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.0010\n",
            "Epoch 41/140\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 1.8929e-04\n",
            "Epoch 42/140\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.0025\n",
            "Epoch 43/140\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.0057\n",
            "Epoch 44/140\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.0079\n",
            "Epoch 45/140\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.0085\n",
            "Epoch 46/140\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0077\n",
            "Epoch 47/140\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.0058\n",
            "Epoch 48/140\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.0036\n",
            "Epoch 49/140\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.0016\n",
            "Epoch 50/140\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 3.7667e-04\n",
            "Epoch 51/140\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 2.2726e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcNGwvUrRlqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "6a31682e-4460-408a-9d8e-aed667540e8b"
      },
      "source": [
        "fig = px.line(df,x=df.index, y='c',template='plotly_dark')\n",
        "fig.add_trace(go.Scatter(x=pred_df.index, y=pred_df[0], mode=\"lines\",name='Test_Prediction'))\n",
        "fig.add_trace(go.Scatter(x=future_pred_df.index, y=future_pred_df[0], mode=\"lines\",name='Future_Prediction'))\n",
        "fig.update_layout(title=stock+' Stock Price LSTM prediction & performance for 15 test days')\n",
        "fig.update_yaxes(title='$')\n",
        "fig.update_xaxes(title='Days')\n",
        "#fig.update_layout(xaxis_rangeslider_visible=True)\n",
        "fig.show()\n",
        "#fig.to_html('pred.html')\n",
        "fig.write_html(stock+' Pred.html')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"df7b7956-6d6c-49bb-81b8-f54376c1c22f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"df7b7956-6d6c-49bb-81b8-f54376c1c22f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'df7b7956-6d6c-49bb-81b8-f54376c1c22f',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>c=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300], \"xaxis\": \"x\", \"y\": [83.365, 85.9975, 88.21, 83.975, 84.7, 85.7475, 88.02, 87.8975, 87.9325, 87.43, 89.7175, 91.6325, 90.015, 91.21, 88.4075, 90.445, 91.2, 91.0275, 91.0275, 93.4625, 93.1725, 95.3425, 95.6825, 95.92, 95.4775, 97.0575, 97.725, 96.5225, 96.3275, 98.3575, 97.0, 97.2725, 92.845, 92.615, 94.81, 93.2525, 95.04, 96.19, 106.26, 108.9375, 109.665, 110.0625, 113.9025, 111.1125, 112.7275, 109.375, 113.01, 115.01, 114.9075, 114.6075, 115.5625, 115.7075, 118.275, 124.37, 125.8575, 124.825, 126.5225, 125.01, 124.8075, 129.04, 134.18, 131.4, 120.88, 120.96, 112.82, 117.32, 113.49, 112.0, 115.355, 115.54, 112.13, 110.34, 106.84, 110.08, 111.81, 107.12, 108.22, 112.28, 114.96, 114.09, 115.81, 116.79, 113.02, 116.5, 113.16, 115.08, 114.97, 116.97, 124.4, 121.1, 121.19, 120.71, 119.02, 115.98, 117.51, 116.87, 115.75, 115.04, 115.05, 116.6, 111.2, 115.32, 108.86, 108.77, 110.44, 114.95, 119.03, 118.69, 116.32, 115.97, 119.49, 119.21, 119.26, 120.3, 119.39, 118.03, 118.64, 117.34, 113.85, 115.17, 116.03, 116.59, 119.05, 122.72, 123.08, 122.94, 122.25, 123.75, 124.38, 121.78, 123.24, 122.41, 121.78, 127.88, 127.81, 128.7, 126.655, 128.23, 131.88, 130.96, 131.97, 136.69, 134.87, 133.72, 132.69, 129.41, 131.01, 126.6, 130.92, 132.05, 128.98, 128.8, 130.89, 128.91, 127.14, 127.83, 132.03, 136.87, 139.07, 142.92, 143.16, 142.06, 137.09, 131.96, 134.14, 134.99, 133.94, 137.39, 136.76, 136.91, 136.01, 135.39, 135.13, 135.37, 133.19, 130.84, 129.71, 129.87, 126.0, 125.86, 125.35, 120.99, 121.26, 127.79, 125.12, 122.06, 120.13, 121.42, 116.36, 121.085, 119.98, 121.96, 121.03, 123.99, 125.57, 124.76, 120.53, 119.99, 123.39, 122.54, 120.09, 120.59, 121.21, 121.39, 119.9, 122.15, 123.0, 125.9, 126.21, 127.9, 130.36, 132.995, 131.24, 134.43, 132.03, 134.5, 134.16, 134.84, 133.11, 133.5, 131.94, 134.32, 134.72, 134.39, 133.58, 133.48, 131.46, 132.54, 127.85, 128.1, 129.74, 130.21, 126.85, 125.91, 122.77, 124.97, 127.45, 126.27, 124.85, 124.69, 127.31, 125.43, 127.1, 126.9, 126.85, 125.28, 124.61, 124.28, 125.06, 123.54, 125.89, 125.9, 126.74, 127.13, 126.11, 127.35, 130.48, 129.64, 130.15, 131.79, 130.46, 132.3, 133.98, 133.7, 133.41, 133.11, 134.78, 136.33, 136.96, 137.27, 139.96, 142.02, 144.57, 143.24, 145.11, 144.5, 145.64, 149.15, 148.48, 146.39, 142.45, 146.15, 145.4, 146.8, 148.56, 148.99, 146.77, 144.98, 145.64, 145.86, 145.52, 147.36, 146.95, 147.06, 146.14, 146.09, 145.6, 145.86, 148.89, 149.1, 151.12], \"yaxis\": \"y\"}, {\"mode\": \"lines\", \"name\": \"Test_Prediction\", \"type\": \"scatter\", \"x\": [286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300], \"y\": [151.42886783301833, 152.5999096685648, 153.79798350930216, 155.03675828039647, 156.32873442173005, 157.68555757522586, 159.1183244299889, 160.63799051582816, 162.25573878586295, 163.98334819912913, 165.83358582973483, 167.8206146603823, 169.9604013758898, 172.27121826291088, 174.77418432056905]}, {\"mode\": \"lines\", \"name\": \"Future_Prediction\", \"type\": \"scatter\", \"x\": [301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315], \"y\": [152.77455442488196, 153.0657958072424, 153.39511228740216, 153.7656539052725, 154.17758220136167, 154.62903945982458, 155.11705333530904, 155.63827993929388, 156.18934307515622, 156.7672461664677, 157.36936417996884, 157.99360516607763, 158.63832948863507, 159.3024144411087, 159.98510886013509]}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#f2f5fa\"}, \"error_y\": {\"color\": \"#f2f5fa\"}, \"marker\": {\"line\": {\"color\": \"rgb(17,17,17)\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"rgb(17,17,17)\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#A2B1C6\", \"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"minorgridcolor\": \"#506784\", \"startlinecolor\": \"#A2B1C6\"}, \"baxis\": {\"endlinecolor\": \"#A2B1C6\", \"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"minorgridcolor\": \"#506784\", \"startlinecolor\": \"#A2B1C6\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"line\": {\"color\": \"#283442\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"line\": {\"color\": \"#283442\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#506784\"}, \"line\": {\"color\": \"rgb(17,17,17)\"}}, \"header\": {\"fill\": {\"color\": \"#2a3f5f\"}, \"line\": {\"color\": \"rgb(17,17,17)\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#f2f5fa\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#f2f5fa\"}, \"geo\": {\"bgcolor\": \"rgb(17,17,17)\", \"lakecolor\": \"rgb(17,17,17)\", \"landcolor\": \"rgb(17,17,17)\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#506784\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"dark\"}, \"paper_bgcolor\": \"rgb(17,17,17)\", \"plot_bgcolor\": \"rgb(17,17,17)\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"bgcolor\": \"rgb(17,17,17)\", \"radialaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}, \"yaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}, \"zaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#f2f5fa\"}}, \"sliderdefaults\": {\"bgcolor\": \"#C8D4E3\", \"bordercolor\": \"rgb(17,17,17)\", \"borderwidth\": 1, \"tickwidth\": 0}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"bgcolor\": \"rgb(17,17,17)\", \"caxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"updatemenudefaults\": {\"bgcolor\": \"#506784\", \"borderwidth\": 0}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#283442\", \"linecolor\": \"#506784\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#283442\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#283442\", \"linecolor\": \"#506784\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#283442\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"AAPL Stock Price LSTM prediction & performance for 15 test days\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Days\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"$\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('df7b7956-6d6c-49bb-81b8-f54376c1c22f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9aVIChWRfjJ"
      },
      "source": [
        "# Visualize The Data"
      ]
    }
  ]
}